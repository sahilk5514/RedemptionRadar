{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\sahil\\anaconda3\\Lib\\site-packages\\pandas\\core\\arrays\\masked.py:61: UserWarning: Pandas requires version '1.3.6' or newer of 'bottleneck' (version '1.3.5' currently installed).\n",
      "  from pandas.core import (\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import lightgbm as lgb\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import roc_auc_score, confusion_matrix\n",
    "import operator\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = 'redemption_status'\n",
    "\n",
    "features = ['age_range',\"rented\",'c_coverage_brand', 'c_coverage_brandt', 'c_coverage_category', 'c_coverage_item', 'c_freq_brand', 'c_freq_brandt', 'c_freq_category', 'c_items_freq_brand', 'c_items_freq_brandt', 'c_items_freq_category', 'c_items_rare_brand', 'c_items_rare_brandt', 'c_items_rare_category', 'c_rare_brand', 'c_rare_brandt', 'c_rare_category', 'c_unique_brand', 'c_unique_brandt', 'c_unique_category', 'c_unique_items', 'campaign_id', 'campaign_type', 'coupon_id', 'customer_id', 'duration', 'family_size', 'income_bracket', 'marital_status', 'no_of_children']\n",
    "\n",
    "categorical_columns = ['age_range', 'c_freq_brand', 'c_freq_brandt', 'c_freq_category', 'c_rare_brand', 'c_rare_brandt', 'c_rare_category', 'campaign_id', 'campaign_type', 'coupon_id', 'customer_id', 'family_size', 'income_bracket', 'marital_status', 'no_of_children', 'rented']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(trainset, testset, categorical_columns, features, target):\n",
    "    # Combine for consistent preprocessing\n",
    "    dataset = pd.concat([trainset, testset], ignore_index=True).copy()\n",
    "\n",
    "    # Fill missing values\n",
    "    dataset = dataset.fillna(0)\n",
    "\n",
    "    # Keep only needed columns\n",
    "    available_features = [col for col in features if col in dataset.columns]\n",
    "    available_categoricals = [col for col in categorical_columns if col in dataset.columns]\n",
    "\n",
    "    # Convert to category dtype\n",
    "    for column in available_categoricals:\n",
    "        dataset[column] = dataset[column].astype('category')\n",
    "\n",
    "    # Select only final features\n",
    "    dataset = dataset[available_features]\n",
    "\n",
    "    # Split back\n",
    "    train_len = len(trainset)\n",
    "    train_features = dataset.iloc[:train_len].reset_index(drop=True)\n",
    "    test_features = dataset.iloc[train_len:].reset_index(drop=True)\n",
    "\n",
    "    # Add back target\n",
    "    trainset = pd.concat([trainset[[target]].reset_index(drop=True), train_features], axis=1)\n",
    "    testset = test_features\n",
    "\n",
    "    return trainset, testset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>redemption_status</th>\n",
       "      <th>campaign_id</th>\n",
       "      <th>coupon_id</th>\n",
       "      <th>customer_id</th>\n",
       "      <th>campaign_type</th>\n",
       "      <th>start_date</th>\n",
       "      <th>end_date</th>\n",
       "      <th>duration</th>\n",
       "      <th>age_range</th>\n",
       "      <th>marital_status</th>\n",
       "      <th>...</th>\n",
       "      <th>overall_coverage_item</th>\n",
       "      <th>overall_coverage_brand</th>\n",
       "      <th>overall_coverage_brandt</th>\n",
       "      <th>overall_coverage_category</th>\n",
       "      <th>overall_podiscount</th>\n",
       "      <th>overall_pcdiscount</th>\n",
       "      <th>overall_ptdiscount</th>\n",
       "      <th>overall_podiscount_pq</th>\n",
       "      <th>overall_pcdiscount_pq</th>\n",
       "      <th>overall_ptdiscount_pq</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>27</td>\n",
       "      <td>1053</td>\n",
       "      <td>0</td>\n",
       "      <td>2013-05-19</td>\n",
       "      <td>2013-07-05</td>\n",
       "      <td>47</td>\n",
       "      <td>46-55</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002808</td>\n",
       "      <td>0.015195</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.421053</td>\n",
       "      <td>-0.219529</td>\n",
       "      <td>-0.001901</td>\n",
       "      <td>-0.221430</td>\n",
       "      <td>-0.226799</td>\n",
       "      <td>-0.002547</td>\n",
       "      <td>-0.229346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>116</td>\n",
       "      <td>48</td>\n",
       "      <td>0</td>\n",
       "      <td>2013-05-19</td>\n",
       "      <td>2013-07-05</td>\n",
       "      <td>47</td>\n",
       "      <td>36-45</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003294</td>\n",
       "      <td>0.018452</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.631579</td>\n",
       "      <td>-0.134105</td>\n",
       "      <td>-0.015566</td>\n",
       "      <td>-0.149671</td>\n",
       "      <td>-0.134672</td>\n",
       "      <td>-0.014163</td>\n",
       "      <td>-0.148835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>635</td>\n",
       "      <td>205</td>\n",
       "      <td>1</td>\n",
       "      <td>2013-03-11</td>\n",
       "      <td>2013-04-12</td>\n",
       "      <td>32</td>\n",
       "      <td>46-55</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.007196</td>\n",
       "      <td>0.033647</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.578947</td>\n",
       "      <td>-0.172274</td>\n",
       "      <td>-0.021414</td>\n",
       "      <td>-0.193688</td>\n",
       "      <td>-0.149134</td>\n",
       "      <td>-0.019910</td>\n",
       "      <td>-0.169044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>644</td>\n",
       "      <td>1050</td>\n",
       "      <td>0</td>\n",
       "      <td>2013-05-19</td>\n",
       "      <td>2013-07-05</td>\n",
       "      <td>47</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002916</td>\n",
       "      <td>0.013205</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.421053</td>\n",
       "      <td>-0.204061</td>\n",
       "      <td>-0.009207</td>\n",
       "      <td>-0.213268</td>\n",
       "      <td>-0.171436</td>\n",
       "      <td>-0.002500</td>\n",
       "      <td>-0.173936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>1017</td>\n",
       "      <td>1489</td>\n",
       "      <td>0</td>\n",
       "      <td>2013-02-16</td>\n",
       "      <td>2013-04-05</td>\n",
       "      <td>48</td>\n",
       "      <td>46-55</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.004415</td>\n",
       "      <td>0.019175</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.421053</td>\n",
       "      <td>-0.205019</td>\n",
       "      <td>-0.004710</td>\n",
       "      <td>-0.209729</td>\n",
       "      <td>-0.202754</td>\n",
       "      <td>-0.006626</td>\n",
       "      <td>-0.209380</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 72 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    redemption_status  campaign_id  coupon_id  customer_id  campaign_type  \\\n",
       "id                                                                          \n",
       "1                   0           13         27         1053              0   \n",
       "2                   0           13        116           48              0   \n",
       "6                   0            9        635          205              1   \n",
       "7                   0           13        644         1050              0   \n",
       "9                   0            8       1017         1489              0   \n",
       "\n",
       "   start_date   end_date  duration age_range  marital_status  ...  \\\n",
       "id                                                            ...   \n",
       "1  2013-05-19 2013-07-05        47     46-55             0.0  ...   \n",
       "2  2013-05-19 2013-07-05        47     36-45             1.0  ...   \n",
       "6  2013-03-11 2013-04-12        32     46-55             1.0  ...   \n",
       "7  2013-05-19 2013-07-05        47       NaN             NaN  ...   \n",
       "9  2013-02-16 2013-04-05        48     46-55             1.0  ...   \n",
       "\n",
       "    overall_coverage_item  overall_coverage_brand  overall_coverage_brandt  \\\n",
       "id                                                                           \n",
       "1                0.002808                0.015195                      1.0   \n",
       "2                0.003294                0.018452                      1.0   \n",
       "6                0.007196                0.033647                      1.0   \n",
       "7                0.002916                0.013205                      1.0   \n",
       "9                0.004415                0.019175                      1.0   \n",
       "\n",
       "    overall_coverage_category  overall_podiscount  overall_pcdiscount  \\\n",
       "id                                                                      \n",
       "1                    0.421053           -0.219529           -0.001901   \n",
       "2                    0.631579           -0.134105           -0.015566   \n",
       "6                    0.578947           -0.172274           -0.021414   \n",
       "7                    0.421053           -0.204061           -0.009207   \n",
       "9                    0.421053           -0.205019           -0.004710   \n",
       "\n",
       "    overall_ptdiscount  overall_podiscount_pq  overall_pcdiscount_pq  \\\n",
       "id                                                                     \n",
       "1            -0.221430              -0.226799              -0.002547   \n",
       "2            -0.149671              -0.134672              -0.014163   \n",
       "6            -0.193688              -0.149134              -0.019910   \n",
       "7            -0.213268              -0.171436              -0.002500   \n",
       "9            -0.209729              -0.202754              -0.006626   \n",
       "\n",
       "    overall_ptdiscount_pq  \n",
       "id                         \n",
       "1               -0.229346  \n",
       "2               -0.148835  \n",
       "6               -0.169044  \n",
       "7               -0.173936  \n",
       "9               -0.209380  \n",
       "\n",
       "[5 rows x 72 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainset = pd.read_csv(r'train1.csv', index_col='id', parse_dates=['start_date','end_date'])\n",
    "trainset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method IndexOpsMixin.value_counts of id\n",
       "1         0.0\n",
       "2         0.0\n",
       "6         0.0\n",
       "7         NaN\n",
       "9         0.0\n",
       "         ... \n",
       "128587    0.0\n",
       "128589    0.0\n",
       "128590    NaN\n",
       "128592    0.0\n",
       "128595    NaN\n",
       "Name: rented, Length: 78369, dtype: float64>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainset['rented'].value_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "print(\"rented\" in trainset.columns)  # should be True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>campaign_id</th>\n",
       "      <th>coupon_id</th>\n",
       "      <th>customer_id</th>\n",
       "      <th>campaign_type</th>\n",
       "      <th>start_date</th>\n",
       "      <th>end_date</th>\n",
       "      <th>duration</th>\n",
       "      <th>age_range</th>\n",
       "      <th>marital_status</th>\n",
       "      <th>rented</th>\n",
       "      <th>...</th>\n",
       "      <th>overall_coverage_item</th>\n",
       "      <th>overall_coverage_brand</th>\n",
       "      <th>overall_coverage_brandt</th>\n",
       "      <th>overall_coverage_category</th>\n",
       "      <th>overall_podiscount</th>\n",
       "      <th>overall_pcdiscount</th>\n",
       "      <th>overall_ptdiscount</th>\n",
       "      <th>overall_podiscount_pq</th>\n",
       "      <th>overall_pcdiscount_pq</th>\n",
       "      <th>overall_ptdiscount_pq</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>22</td>\n",
       "      <td>869</td>\n",
       "      <td>967</td>\n",
       "      <td>0</td>\n",
       "      <td>2013-09-16</td>\n",
       "      <td>2013-10-18</td>\n",
       "      <td>32</td>\n",
       "      <td>36-45</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.008884</td>\n",
       "      <td>0.038531</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.684211</td>\n",
       "      <td>-0.116013</td>\n",
       "      <td>-0.015037</td>\n",
       "      <td>-0.131051</td>\n",
       "      <td>-0.112131</td>\n",
       "      <td>-0.015335</td>\n",
       "      <td>-0.127466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20</td>\n",
       "      <td>389</td>\n",
       "      <td>1566</td>\n",
       "      <td>1</td>\n",
       "      <td>2013-09-07</td>\n",
       "      <td>2013-11-16</td>\n",
       "      <td>70</td>\n",
       "      <td>26-35</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.016391</td>\n",
       "      <td>0.053003</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.789474</td>\n",
       "      <td>-0.123949</td>\n",
       "      <td>-0.005637</td>\n",
       "      <td>-0.129586</td>\n",
       "      <td>-0.129240</td>\n",
       "      <td>-0.005853</td>\n",
       "      <td>-0.135093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>22</td>\n",
       "      <td>981</td>\n",
       "      <td>510</td>\n",
       "      <td>0</td>\n",
       "      <td>2013-09-16</td>\n",
       "      <td>2013-10-18</td>\n",
       "      <td>32</td>\n",
       "      <td>26-35</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.013758</td>\n",
       "      <td>0.037988</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.578947</td>\n",
       "      <td>-0.322410</td>\n",
       "      <td>-0.019489</td>\n",
       "      <td>-0.341900</td>\n",
       "      <td>-0.332639</td>\n",
       "      <td>-0.019500</td>\n",
       "      <td>-0.352139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>25</td>\n",
       "      <td>1069</td>\n",
       "      <td>361</td>\n",
       "      <td>1</td>\n",
       "      <td>2013-10-21</td>\n",
       "      <td>2013-11-22</td>\n",
       "      <td>32</td>\n",
       "      <td>18-25</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.004361</td>\n",
       "      <td>0.021346</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.421053</td>\n",
       "      <td>-0.185940</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.185940</td>\n",
       "      <td>-0.179631</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.179631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>17</td>\n",
       "      <td>498</td>\n",
       "      <td>811</td>\n",
       "      <td>1</td>\n",
       "      <td>2013-07-29</td>\n",
       "      <td>2013-08-30</td>\n",
       "      <td>32</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.009721</td>\n",
       "      <td>0.037808</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.578947</td>\n",
       "      <td>-0.196402</td>\n",
       "      <td>-0.000910</td>\n",
       "      <td>-0.197312</td>\n",
       "      <td>-0.184152</td>\n",
       "      <td>-0.000647</td>\n",
       "      <td>-0.184799</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 71 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    campaign_id  coupon_id  customer_id  campaign_type start_date   end_date  \\\n",
       "id                                                                             \n",
       "3            22        869          967              0 2013-09-16 2013-10-18   \n",
       "4            20        389         1566              1 2013-09-07 2013-11-16   \n",
       "5            22        981          510              0 2013-09-16 2013-10-18   \n",
       "8            25       1069          361              1 2013-10-21 2013-11-22   \n",
       "10           17        498          811              1 2013-07-29 2013-08-30   \n",
       "\n",
       "    duration age_range  marital_status  rented  ...  overall_coverage_item  \\\n",
       "id                                              ...                          \n",
       "3         32     36-45             0.0     0.0  ...               0.008884   \n",
       "4         70     26-35             1.0     0.0  ...               0.016391   \n",
       "5         32     26-35             0.0     0.0  ...               0.013758   \n",
       "8         32     18-25             0.0     0.0  ...               0.004361   \n",
       "10        32       NaN             NaN     NaN  ...               0.009721   \n",
       "\n",
       "    overall_coverage_brand  overall_coverage_brandt  \\\n",
       "id                                                    \n",
       "3                 0.038531                      1.0   \n",
       "4                 0.053003                      1.0   \n",
       "5                 0.037988                      1.0   \n",
       "8                 0.021346                      1.0   \n",
       "10                0.037808                      1.0   \n",
       "\n",
       "    overall_coverage_category  overall_podiscount  overall_pcdiscount  \\\n",
       "id                                                                      \n",
       "3                    0.684211           -0.116013           -0.015037   \n",
       "4                    0.789474           -0.123949           -0.005637   \n",
       "5                    0.578947           -0.322410           -0.019489   \n",
       "8                    0.421053           -0.185940            0.000000   \n",
       "10                   0.578947           -0.196402           -0.000910   \n",
       "\n",
       "    overall_ptdiscount  overall_podiscount_pq  overall_pcdiscount_pq  \\\n",
       "id                                                                     \n",
       "3            -0.131051              -0.112131              -0.015335   \n",
       "4            -0.129586              -0.129240              -0.005853   \n",
       "5            -0.341900              -0.332639              -0.019500   \n",
       "8            -0.185940              -0.179631               0.000000   \n",
       "10           -0.197312              -0.184152              -0.000647   \n",
       "\n",
       "    overall_ptdiscount_pq  \n",
       "id                         \n",
       "3               -0.127466  \n",
       "4               -0.135093  \n",
       "5               -0.352139  \n",
       "8               -0.179631  \n",
       "10              -0.184799  \n",
       "\n",
       "[5 rows x 71 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testset = pd.read_csv(r'test1.csv', index_col='id', parse_dates=['start_date','end_date'])\n",
    "testset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainset size: (78369, 32)\n",
      "Testset size: (50226, 31)\n"
     ]
    }
   ],
   "source": [
    "trainset, testset = preprocess(trainset, testset, categorical_columns, features, target)\n",
    "\n",
    "print(\"Trainset size: {}\".format(trainset.shape))\n",
    "print(\"Testset size: {}\".format(testset.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset[\"campaign_id\"] = trainset[\"campaign_id\"].astype(int)\n",
    "val2_ids = trainset[trainset.campaign_id > 25].index\n",
    "sub_trainset = trainset[trainset.campaign_id < 26]\n",
    "\n",
    "train_ids = []\n",
    "val1_ids = []\n",
    "for campaign in sub_trainset.campaign_id.unique():\n",
    "    campaign_rows = sub_trainset[sub_trainset.campaign_id == campaign].index\n",
    "    train, val = train_test_split(campaign_rows, test_size=0.2, random_state=41)\n",
    "    train_ids.extend(train)\n",
    "    val1_ids.extend(val)\n",
    "\n",
    "# Now this will work\n",
    "val1set = trainset.loc[val1_ids]\n",
    "val2set = trainset.loc[val2_ids]\n",
    "trainset = trainset.loc[train_ids]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_columns = features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Ensemble():\n",
    "    def __init__(self, models):\n",
    "        self.__models = models\n",
    "    \n",
    "    def predict(self, data):\n",
    "        pred_sum = np.zeros(len(data))\n",
    "        for model in self.__models:\n",
    "            pred_sum = pred_sum + model.predict(data, num_iteration=model.best_iteration)\n",
    "        return pred_sum / len(self.__models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(X_train, y_train, X_val, y_val, num_leaves, verbose=True):\n",
    "    import lightgbm as lgb\n",
    "    from sklearn.metrics import roc_auc_score\n",
    "\n",
    "    params = {\n",
    "        \"objective\": \"binary\",\n",
    "        \"boosting_type\": \"gbdt\",\n",
    "        \"metric\": \"auc\",\n",
    "        \"verbosity\": -1,\n",
    "        \"num_leaves\": num_leaves,\n",
    "        \"learning_rate\": 0.05,\n",
    "    }\n",
    "\n",
    "    lgtrain = lgb.Dataset(X_train, label=y_train)\n",
    "    lgval = lgb.Dataset(X_val, label=y_val)\n",
    "\n",
    "    evals_result = {}\n",
    "\n",
    "    model = lgb.train(\n",
    "        params,\n",
    "        lgtrain,\n",
    "        num_boost_round=1000,\n",
    "        valid_sets=[lgval],\n",
    "        valid_names=['valid_0'],\n",
    "        callbacks=[\n",
    "            lgb.early_stopping(stopping_rounds=50),\n",
    "            lgb.record_evaluation(evals_result)\n",
    "        ],\n",
    "        verbose_eval=verbose\n",
    "    )\n",
    "\n",
    "    score = evals_result['valid_0']['auc'][-1]\n",
    "\n",
    "    if verbose:\n",
    "        print(\"num_leaves {}: AUC = {:.4f}\".format(num_leaves, score))\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(X_train, y_train, X_val, y_val, num_leaves, verbose=True):\n",
    "    import lightgbm as lgb\n",
    "    from sklearn.metrics import roc_auc_score\n",
    "\n",
    "    params = {\n",
    "        \"objective\": \"binary\",\n",
    "        \"boosting_type\": \"gbdt\",\n",
    "        \"metric\": \"auc\",\n",
    "        \"verbosity\": -1,\n",
    "        \"num_leaves\": num_leaves,\n",
    "        \"learning_rate\": 0.05,\n",
    "    }\n",
    "\n",
    "    lgtrain = lgb.Dataset(X_train, label=y_train)\n",
    "    lgval = lgb.Dataset(X_val, label=y_val)\n",
    "\n",
    "    evals_result = {}\n",
    "\n",
    "    model = lgb.train(\n",
    "        params,\n",
    "        lgtrain,\n",
    "        num_boost_round=1000,\n",
    "        valid_sets=[lgval],\n",
    "        valid_names=['valid_0'],\n",
    "        callbacks=[\n",
    "            lgb.early_stopping(stopping_rounds=50),\n",
    "            lgb.record_evaluation(evals_result)\n",
    "        ],\n",
    "        verbose_eval=verbose\n",
    "    )\n",
    "\n",
    "    score = evals_result['valid_0']['auc'][-1]\n",
    "\n",
    "    if verbose:\n",
    "        print(\"num_leaves {}: AUC = {:.4f}\".format(num_leaves, score))\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_lgbm(features, verbose=False):\n",
    "    X_train, y_train = trainset[features], trainset[target]\n",
    "    X_val1, y_val1 = val1set[features], val1set[target]\n",
    "    X_val2, y_val2 = val2set[features], val2set[target]\n",
    "    \n",
    "    models = [train(X_train, y_train, X_val1, y_val1, num_leaves, verbose) for num_leaves in [15, 20, 25]]\n",
    "    ensemble_model = Ensemble(models)\n",
    "    \n",
    "    score1 = roc_auc_score(y_val1, ensemble_model.predict(X_val1))\n",
    "    score2 = roc_auc_score(y_val2, ensemble_model.predict(X_val2))\n",
    "    score3 = roc_auc_score(y_train, ensemble_model.predict(X_train))\n",
    "    print(\"Classification Report for Validation Set 1:\")\n",
    "    print(classification_report(y_val1, val1_preds))\n",
    "    \n",
    "    print(\"Classification Report for Validation Set 2:\")\n",
    "    print(classification_report(y_val2, val2_preds))\n",
    "    \n",
    "    print(\"Classification Report for Training Set:\")\n",
    "    print(classification_report(y_train, train_preds))\n",
    "\n",
    "    return ensemble_model, score1, score2, score3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "train() got an unexpected keyword argument 'verbose_eval'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[16], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m all_model, all_score1, all_score2, all_score3 \u001b[38;5;241m=\u001b[39m run_lgbm(feature_columns, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mScore 1 (Validation Set 1):\u001b[39m\u001b[38;5;124m\"\u001b[39m, all_score1)\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mScore 2 (Validation Set 2):\u001b[39m\u001b[38;5;124m\"\u001b[39m, all_score2)\n",
      "Cell \u001b[1;32mIn[14], line 6\u001b[0m, in \u001b[0;36mrun_lgbm\u001b[1;34m(features, verbose)\u001b[0m\n\u001b[0;32m      3\u001b[0m X_val1, y_val1 \u001b[38;5;241m=\u001b[39m val1set[features], val1set[target]\n\u001b[0;32m      4\u001b[0m X_val2, y_val2 \u001b[38;5;241m=\u001b[39m val2set[features], val2set[target]\n\u001b[1;32m----> 6\u001b[0m models \u001b[38;5;241m=\u001b[39m [train(X_train, y_train, X_val1, y_val1, num_leaves, verbose) \u001b[38;5;28;01mfor\u001b[39;00m num_leaves \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;241m15\u001b[39m, \u001b[38;5;241m20\u001b[39m, \u001b[38;5;241m25\u001b[39m]]\n\u001b[0;32m      7\u001b[0m ensemble_model \u001b[38;5;241m=\u001b[39m Ensemble(models)\n\u001b[0;32m      9\u001b[0m score1 \u001b[38;5;241m=\u001b[39m roc_auc_score(y_val1, ensemble_model\u001b[38;5;241m.\u001b[39mpredict(X_val1))\n",
      "Cell \u001b[1;32mIn[14], line 6\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m      3\u001b[0m X_val1, y_val1 \u001b[38;5;241m=\u001b[39m val1set[features], val1set[target]\n\u001b[0;32m      4\u001b[0m X_val2, y_val2 \u001b[38;5;241m=\u001b[39m val2set[features], val2set[target]\n\u001b[1;32m----> 6\u001b[0m models \u001b[38;5;241m=\u001b[39m [train(X_train, y_train, X_val1, y_val1, num_leaves, verbose) \u001b[38;5;28;01mfor\u001b[39;00m num_leaves \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;241m15\u001b[39m, \u001b[38;5;241m20\u001b[39m, \u001b[38;5;241m25\u001b[39m]]\n\u001b[0;32m      7\u001b[0m ensemble_model \u001b[38;5;241m=\u001b[39m Ensemble(models)\n\u001b[0;32m      9\u001b[0m score1 \u001b[38;5;241m=\u001b[39m roc_auc_score(y_val1, ensemble_model\u001b[38;5;241m.\u001b[39mpredict(X_val1))\n",
      "Cell \u001b[1;32mIn[13], line 19\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(X_train, y_train, X_val, y_val, num_leaves, verbose)\u001b[0m\n\u001b[0;32m     15\u001b[0m lgval \u001b[38;5;241m=\u001b[39m lgb\u001b[38;5;241m.\u001b[39mDataset(X_val, label\u001b[38;5;241m=\u001b[39my_val)\n\u001b[0;32m     17\u001b[0m evals_result \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m---> 19\u001b[0m model \u001b[38;5;241m=\u001b[39m lgb\u001b[38;5;241m.\u001b[39mtrain(\n\u001b[0;32m     20\u001b[0m     params,\n\u001b[0;32m     21\u001b[0m     lgtrain,\n\u001b[0;32m     22\u001b[0m     num_boost_round\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1000\u001b[39m,\n\u001b[0;32m     23\u001b[0m     valid_sets\u001b[38;5;241m=\u001b[39m[lgval],\n\u001b[0;32m     24\u001b[0m     valid_names\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvalid_0\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[0;32m     25\u001b[0m     callbacks\u001b[38;5;241m=\u001b[39m[\n\u001b[0;32m     26\u001b[0m         lgb\u001b[38;5;241m.\u001b[39mearly_stopping(stopping_rounds\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m50\u001b[39m),\n\u001b[0;32m     27\u001b[0m         lgb\u001b[38;5;241m.\u001b[39mrecord_evaluation(evals_result)\n\u001b[0;32m     28\u001b[0m     ],\n\u001b[0;32m     29\u001b[0m     verbose_eval\u001b[38;5;241m=\u001b[39mverbose\n\u001b[0;32m     30\u001b[0m )\n\u001b[0;32m     32\u001b[0m score \u001b[38;5;241m=\u001b[39m evals_result[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvalid_0\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mauc\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m     34\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m verbose:\n",
      "\u001b[1;31mTypeError\u001b[0m: train() got an unexpected keyword argument 'verbose_eval'"
     ]
    }
   ],
   "source": [
    "all_model, all_score1, all_score2, all_score3 = run_lgbm(feature_columns, verbose=True)\n",
    "print(\"Score 1 (Validation Set 1):\", all_score1)\n",
    "print(\"Score 2 (Validation Set 2):\", all_score2)\n",
    "print(\"Score 3 (Training Set):\", all_score3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature Verification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# %%time\n",
    "\n",
    "# def exclude_feature(features, index):\n",
    "#     new_features = features[:index] + features[index+1:]\n",
    "#     model, _, score, _ = train(new_features)\n",
    "#     return score\n",
    "\n",
    "# score_map = {}\n",
    "# for index, name in enumerate(feature_columns):\n",
    "#     score = exclude_feature(feature_columns, index) - all_score2\n",
    "#     print(\"{}: {}\".format(name, score))\n",
    "#     score_map[name] = score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# score_map = sorted(score_map.items(), key=operator.itemgetter(1), reverse=True)\n",
    "# score_map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: catboost in c:\\users\\sahil\\anaconda3\\lib\\site-packages (1.2.8)\n",
      "Requirement already satisfied: graphviz in c:\\users\\sahil\\anaconda3\\lib\\site-packages (from catboost) (0.20.3)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\sahil\\anaconda3\\lib\\site-packages (from catboost) (3.7.2)\n",
      "Requirement already satisfied: numpy<3.0,>=1.16.0 in c:\\users\\sahil\\anaconda3\\lib\\site-packages (from catboost) (1.24.3)\n",
      "Requirement already satisfied: pandas>=0.24 in c:\\users\\sahil\\anaconda3\\lib\\site-packages (from catboost) (2.0.3)\n",
      "Requirement already satisfied: scipy in c:\\users\\sahil\\anaconda3\\lib\\site-packages (from catboost) (1.11.1)\n",
      "Requirement already satisfied: plotly in c:\\users\\sahil\\anaconda3\\lib\\site-packages (from catboost) (5.9.0)\n",
      "Requirement already satisfied: six in c:\\users\\sahil\\anaconda3\\lib\\site-packages (from catboost) (1.16.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\sahil\\anaconda3\\lib\\site-packages (from pandas>=0.24->catboost) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\sahil\\anaconda3\\lib\\site-packages (from pandas>=0.24->catboost) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\users\\sahil\\anaconda3\\lib\\site-packages (from pandas>=0.24->catboost) (2023.3)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\sahil\\anaconda3\\lib\\site-packages (from matplotlib->catboost) (1.0.5)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\sahil\\anaconda3\\lib\\site-packages (from matplotlib->catboost) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\sahil\\anaconda3\\lib\\site-packages (from matplotlib->catboost) (4.25.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\sahil\\anaconda3\\lib\\site-packages (from matplotlib->catboost) (1.4.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\sahil\\anaconda3\\lib\\site-packages (from matplotlib->catboost) (23.1)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\sahil\\anaconda3\\lib\\site-packages (from matplotlib->catboost) (9.4.0)\n",
      "Requirement already satisfied: pyparsing<3.1,>=2.3.1 in c:\\users\\sahil\\anaconda3\\lib\\site-packages (from matplotlib->catboost) (3.0.9)\n",
      "Requirement already satisfied: tenacity>=6.2.0 in c:\\users\\sahil\\anaconda3\\lib\\site-packages (from plotly->catboost) (8.2.2)\n"
     ]
    }
   ],
   "source": [
    "#! pip install catboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = \"redemption_status\"\n",
    "X = trainset.drop(columns=[target])\n",
    "y = trainset[target]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace NaN values with a placeholder (e.g., 'missing') in categorical columns\n",
    "for cat_column in categorical_columns:\n",
    "    if X_train[cat_column].isnull().any():  # Check if there are NaN values in the column\n",
    "        X_train[cat_column] = X_train[cat_column].fillna('missing')\n",
    "    if X_val[cat_column].isnull().any():  # Check if there are NaN values in the column in validation set\n",
    "        X_val[cat_column] = X_val[cat_column].fillna('missing')\n",
    "\n",
    "# Convert categorical columns to string (or integer if appropriate)\n",
    "X_train[categorical_columns] = X_train[categorical_columns].astype(str)\n",
    "X_val[categorical_columns] = X_val[categorical_columns].astype(str)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\ttest: 0.6707571\tbest: 0.6707571 (0)\ttotal: 296ms\tremaining: 2m 27s\n",
      "100:\ttest: 0.9164169\tbest: 0.9164169 (100)\ttotal: 8.95s\tremaining: 35.3s\n",
      "200:\ttest: 0.9233444\tbest: 0.9236097 (180)\ttotal: 19.1s\tremaining: 28.4s\n",
      "300:\ttest: 0.9240039\tbest: 0.9240588 (296)\ttotal: 29.5s\tremaining: 19.5s\n",
      "Stopped by overfitting detector  (50 iterations wait)\n",
      "\n",
      "bestTest = 0.9240588383\n",
      "bestIteration = 296\n",
      "\n",
      "Shrink model to first 297 iterations.\n",
      "Validation Accuracy: 0.9910057236304171\n",
      "Validation AUC: 0.924058838306806\n"
     ]
    }
   ],
   "source": [
    "from catboost import CatBoostClassifier\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "\n",
    "model = CatBoostClassifier(\n",
    "    iterations=500,\n",
    "    learning_rate=0.05,\n",
    "    depth=6,\n",
    "    eval_metric='AUC',\n",
    "    early_stopping_rounds=50,\n",
    "    verbose=100\n",
    ")\n",
    "\n",
    "# Fit on train-validation split\n",
    "model.fit(X_train, y_train,cat_features=categorical_columns, eval_set=(X_val, y_val))\n",
    "\n",
    "# Evaluate\n",
    "val_preds = model.predict(X_val)\n",
    "val_probs = model.predict_proba(X_val)[:, 1]\n",
    "print(\"Validation Accuracy:\", accuracy_score(y_val, val_preds))\n",
    "print(\"Validation AUC:\", roc_auc_score(y_val, val_probs))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "cm = confusion_matrix(y_val, val_preds)\n",
    "\n",
    "# Plot the confusion matrix using Seaborn heatmap\n",
    "plt.figure(figsize=(6, 5))\n",
    "sns.heatmap(cm, annot=True, fmt='g', cmap='Blues', xticklabels=['Class 0', 'Class 1'], yticklabels=['Class 0', 'Class 1'])\n",
    "plt.xlabel('Predicted Labels')\n",
    "plt.ylabel('True Labels')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9910057236304171\n",
      "Precision: 0.6428571428571429\n",
      "Recall: 0.09782608695652174\n",
      "F1-Score: 0.16981132075471697\n",
      "ROC-AUC: 0.924058838306806\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      1.00      9692\n",
      "           1       0.64      0.10      0.17        92\n",
      "\n",
      "    accuracy                           0.99      9784\n",
      "   macro avg       0.82      0.55      0.58      9784\n",
      "weighted avg       0.99      0.99      0.99      9784\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, classification_report\n",
    "\n",
    "# Assuming you have the true labels in y_val and the predicted labels in val_preds\n",
    "y_val = y_val  # True labels from the validation set\n",
    "val_preds = model.predict(X_val)  # Predicted labels from the model\n",
    "\n",
    "# Calculate Accuracy\n",
    "accuracy = accuracy_score(y_val, val_preds)\n",
    "\n",
    "# Calculate Precision\n",
    "precision = precision_score(y_val, val_preds)\n",
    "\n",
    "# Calculate Recall\n",
    "recall = recall_score(y_val, val_preds)\n",
    "\n",
    "# Calculate F1-Score\n",
    "f1 = f1_score(y_val, val_preds)\n",
    "\n",
    "# Calculate ROC-AUC (if binary classification)\n",
    "roc_auc = roc_auc_score(y_val, model.predict_proba(X_val)[:, 1])  # For binary classification, take the probability of class 1\n",
    "\n",
    "# Print all metrics\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"F1-Score:\", f1)\n",
    "print(\"ROC-AUC:\", roc_auc)\n",
    "\n",
    "# Detailed classification report\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_val, val_preds))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
